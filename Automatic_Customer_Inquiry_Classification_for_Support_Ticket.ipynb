{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bExk9Qnfeiad",
        "outputId": "c6f34131-7dc6-4461-8d51-c57ea27a5f0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: textblob in /usr/local/lib/python3.10/dist-packages (0.17.1)\n",
            "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.10/dist-packages (from textblob) (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (4.66.6)\n"
          ]
        }
      ],
      "source": [
        "!pip install textblob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "id": "x2fyhkgJRsPn"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re, nltk, spacy, string\n",
        "import en_core_web_sm\n",
        "nlp = en_core_web_sm.load()\n",
        "from textblob import TextBlob\n",
        "\n",
        "#Importing libraries required for the case study and to plot charts\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "from plotly.offline import plot\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "%matplotlib inline\n",
        "\n",
        "#Importing Regular Expressions for String manipulation\n",
        "import re\n",
        "\n",
        "# hide warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "id": "mJT9-BAKSBbV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "8fa93038-58ca-4396-fef1-bd3ec3147731"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "expected an indented block after 'with' statement on line 7 (<ipython-input-144-ad611ec10058>, line 8)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-144-ad611ec10058>\"\u001b[0;36m, line \u001b[0;32m8\u001b[0m\n\u001b[0;31m    data = json.load(j)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after 'with' statement on line 7\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "with open('/content/complaints-2021-05-14_08_16.json', encoding='latin-1') as j:\n",
        "data = json.load(j)\n",
        "\n",
        "df = pd.json_normalize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "INvRqm8GS9iy"
      },
      "outputs": [],
      "source": [
        "# Inspect the dataframe to understand the given data.\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uzws7X45TBbJ"
      },
      "outputs": [],
      "source": [
        "#shape of dataframe\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PavfeMLQTD3o"
      },
      "outputs": [],
      "source": [
        "#print the column names\n",
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fja0rqotTG6i"
      },
      "outputs": [],
      "source": [
        "#Assign new column names\n",
        "df = df[['_source.complaint_what_happened','_source.product','_source.sub_product',]]\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SK6cRJ3sVfQM"
      },
      "outputs": [],
      "source": [
        "# lets rename the column names to be more read friendly\n",
        "\n",
        "df = df.rename(columns={'_source.complaint_what_happened': 'complaint_text', '_source.product': 'category','_source.sub_product': 'sub_category'})\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d1K8fwvFVjt9"
      },
      "outputs": [],
      "source": [
        "# lets merge the category and sub-category this will help us in deciding the topics after NMF modelling\n",
        "df['category'] = df['category'] + '+' + df['sub_category']\n",
        "df = df.drop(['sub_category'],axis= 1)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5anQHsltVnAH"
      },
      "outputs": [],
      "source": [
        "# lets check the nan complaints\n",
        "df.complaint_text.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DIZWPS6NVqEA"
      },
      "outputs": [],
      "source": [
        "# lets check the empty string complaints\n",
        "len(df[df['complaint_text']==''])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1REXE9NCVsWT"
      },
      "outputs": [],
      "source": [
        "#Assign nan in place of blanks in the complaints column\n",
        "# lets replace empty complain with nan value\n",
        "df[df['complaint_text']==''] = np.nan\n",
        "df.complaint_text.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_r8czei2VuyE"
      },
      "outputs": [],
      "source": [
        "#Remove all rows where complaints column is nan\n",
        "# Lets drop all the rows where complaint_text is null\n",
        "df = df[~df['complaint_text'].isnull()]\n",
        "df.complaint_text.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EdtzQrIwadtl"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tu-yyD3PaKTD"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ciKGBdwiaT17"
      },
      "outputs": [],
      "source": [
        "# Write your function here to clean the text and remove all the unnecessary elements.\n",
        "def clean_texts(text):\n",
        "    #Make the text lowercase\n",
        "    text=text.lower()\n",
        "\n",
        "    #Remove text in square brackets\n",
        "    text=re.sub(r'\\[.*?\\]','',text)\n",
        "\n",
        "    #Remove punctuation\n",
        "    text=re.sub(r'[%s]%re.escape(string.punctuation)','',text)\n",
        "\n",
        "    #Remove words containing numbers\n",
        "    text = re.sub(r'\\w*\\d\\w*', '', text)\n",
        "\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ay-zsH9aTyj"
      },
      "outputs": [],
      "source": [
        "#Cleaning df['complaint_what_happened']\n",
        "df['complaint_text']= df['complaint_text'].apply(lambda x: clean_texts(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PQhf3mj9atxw"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PYvIk4G2aTvr"
      },
      "outputs": [],
      "source": [
        "#Write your function to Lemmatize the texts\n",
        "def lemma_texts(text):\n",
        "\n",
        "    # Initialize empty list to store lemmas\n",
        "    lemma_list = []\n",
        "\n",
        "    # Extract lemmas of given text and add to the list 'sent'\n",
        "    document = nlp(text)\n",
        "    for word in document:\n",
        "        lemma_list.append(word.lemma_)\n",
        "\n",
        "    # return string converted form of the list of lemmas\n",
        "    return \" \".join(lemma_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u4hSJ2FAaTpz"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def lemma_texts_batch(texts):\n",
        "    \"\"\"Lemmatizes a batch of texts using spaCy's nlp.pipe for efficiency.\"\"\"\n",
        "    docs = nlp.pipe(texts, disable=[\"parser\", \"ner\"])  # Disable unnecessary components\n",
        "    return [\" \".join([token.lemma_ for token in doc]) for doc in docs]\n",
        "\n",
        "df[\"lemmatized_complaint\"] = lemma_texts_batch(df[\"complaint_text\"].tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8QhKnoMWaTmN"
      },
      "outputs": [],
      "source": [
        "#Create a dataframe('df_clean') that will have only the complaints and the lemmatized complaints\n",
        "df_clean=df[['complaint_text','lemmatized_complaint']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CkMnokMcayAk"
      },
      "outputs": [],
      "source": [
        "df_clean.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "77pARvh1ev2z"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eTBMpKtYe2y8"
      },
      "outputs": [],
      "source": [
        "nltk.download('averaged_perceptron_tagger')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZJ9udsW-YfQ9"
      },
      "outputs": [],
      "source": [
        "#Write your function to extract the POS tags\n",
        "\n",
        "# Extracting singular nouns\n",
        "def singular_nouns(text):\n",
        "\n",
        "\n",
        "    # Creating a textblob object\n",
        "    text_blob = TextBlob(text)\n",
        "\n",
        "    # extracting words with tags 'NN', joining them and return\n",
        "    return ' '.join([ word for (word,tag) in text_blob.tags if tag == \"NN\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rDSIizmkd596"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "df_clean[\"complaint_POS_removed\"] = df_clean.apply(lambda x: singular_nouns(x['lemmatized_complaint']), axis=1)\n",
        "\n",
        "# View the dataframe\n",
        "df_clean.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Exploratory Data Analysis"
      ],
      "metadata": {
        "id": "ChvqgiP3lRvZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "su7fTxHJd9ab"
      },
      "outputs": [],
      "source": [
        "#lenght of character in 'complaint_POS_removed'\n",
        "char_len=[len(x) for x in df_clean['complaint_POS_removed']]\n",
        "char_len[:15]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H5-ZmLwjiEU1"
      },
      "outputs": [],
      "source": [
        "## Write your code here to visualise the data according to the 'Complaint' character length\n",
        "plt.figure(figsize=[10,6])\n",
        "sns.histplot(data = char_len,bins=55)\n",
        "plt.title('Distribution of Complaint Character Length', fontsize=25)\n",
        "plt.xlabel('Complaint Character Length',size=20)\n",
        "plt.ylabel('No. of Complaints',size=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EKT5CL07iLya"
      },
      "outputs": [],
      "source": [
        "!pip install wordcloud"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "79d5ck36iZeU"
      },
      "outputs": [],
      "source": [
        "#Using a word cloud find the top 40 words by frequency among all the articles after processing the text\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "\n",
        "stop_words = set(STOPWORDS)\n",
        "word_cloud = WordCloud(\n",
        "                          background_color='green',\n",
        "                          stopwords=stop_words,\n",
        "                          max_font_size=38,\n",
        "                          max_words=38,\n",
        "                          random_state=42\n",
        "                         ).generate(str(df_clean['complaint_POS_removed']))\n",
        "\n",
        "fig = plt.figure(figsize=(20,16))\n",
        "plt.imshow(word_cloud)\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ZetpccRnYTy"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BjLC-WTKiqYJ"
      },
      "outputs": [],
      "source": [
        "def get_top_n_bigram(text, ngram=1, top=None):\n",
        "    vec = CountVectorizer(ngram_range=(ngram, ngram), stop_words='english').fit(text)\n",
        "    bag_of_words = vec.transform(text)\n",
        "\n",
        "    sum_words = bag_of_words.sum(axis=0)\n",
        "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
        "\n",
        "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
        "    return words_freq[:top]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l8dnrOuRm_Iz"
      },
      "outputs": [],
      "source": [
        "top_30_unigrams = get_top_n_bigram(df_clean.complaint_POS_removed, ngram=1, top=30)\n",
        "top_30_bigrams = get_top_n_bigram(df_clean.complaint_POS_removed, ngram=2, top=30)\n",
        "top_30_trigrams = get_top_n_bigram(df_clean.complaint_POS_removed, ngram=3, top=30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5GYVZ6A3nOjg"
      },
      "outputs": [],
      "source": [
        "#Print the top 10 words in the unigram frequency\n",
        "print('Top 10 unigrams:\\n')\n",
        "\n",
        "df_unigram = pd.DataFrame(top_30_unigrams, columns = ['unigram' , 'count'])\n",
        "df_unigram.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "88KDpe4GngUr"
      },
      "outputs": [],
      "source": [
        "# Plot the top 30 unigrams\n",
        "plt.figure(figsize=(12,6))\n",
        "sns.barplot(x='unigram', y='count', data=df_unigram, palette=\"Blues_d\")\n",
        "plt.xticks(rotation=90)\n",
        "plt.title(\"Top 30 unigrams in the Complaint text after removing stop words and lemmatization\", fontsize=20)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N9g8r-02oOaD"
      },
      "outputs": [],
      "source": [
        "#Print the top 10 words in the bigram frequency\n",
        "print('Top 10 bigrams:\\n')\n",
        "\n",
        "df_bigram = pd.DataFrame(top_30_bigrams, columns = ['bigram' , 'count'])\n",
        "df_bigram.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c3eGiEGgos2U"
      },
      "outputs": [],
      "source": [
        "# Plot the top 30 bigrams\n",
        "plt.figure(figsize=(12,6))\n",
        "sns.barplot(x='bigram', y='count', data=df_bigram, palette=\"Blues_d\")\n",
        "plt.xticks(rotation=90)\n",
        "plt.title(\"Top 30 bigrams in the Complaint text after removing stop words and lemmatization\", fontsize=20)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e2_-CIuIoy4g"
      },
      "outputs": [],
      "source": [
        "#Print the top 10 words in the trigram frequency\n",
        "print('Top 10 trigrams:\\n')\n",
        "\n",
        "df_trigram = pd.DataFrame(top_30_trigrams, columns = ['trigram' , 'count'])\n",
        "df_trigram.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f1SVyVSppBXe"
      },
      "outputs": [],
      "source": [
        "# Plot the top 30 trigrams\n",
        "plt.figure(figsize=(15,6))\n",
        "sns.barplot(x='trigram', y='count', data=df_trigram, palette=\"Blues_d\")\n",
        "plt.xticks(rotation=90)\n",
        "plt.title(\"Top 30 trigrams in the Complaint text after removing stop words and lemmatization\", fontsize=20)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h-O2C3SWpJVp"
      },
      "outputs": [],
      "source": [
        "df_clean['complaint_POS_removed'] = df_clean['complaint_POS_removed'].str.replace('xxxx','')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PAa5epKrpRJw"
      },
      "outputs": [],
      "source": [
        "#All masked texts has been removed\n",
        "df_clean.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TG0SzOH0pmv9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Feature Extraction"
      ],
      "metadata": {
        "id": "BdV4pkdPlYAU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i9g7D56epTLo"
      },
      "outputs": [],
      "source": [
        "#Write your code here to initialise the TfidfVectorizer\n",
        "tfidf = TfidfVectorizer(min_df=2, max_df=0.95, stop_words='english')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LbNq8JdBpn5v"
      },
      "outputs": [],
      "source": [
        "#Write your code here to create the Document Term Matrix by transforming the complaints column present in df_clean.\n",
        "dtm = tfidf.fit_transform(df_clean.complaint_POS_removed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LaLwyg9aqP-C"
      },
      "outputs": [],
      "source": [
        "dtm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "15xOBplHqYK6"
      },
      "outputs": [],
      "source": [
        "# Use get_feature_names_out() instead of get_feature_names()\n",
        "tfidf.get_feature_names_out()[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Topic Modelling using NMF (Non-Matrix Factorization)"
      ],
      "metadata": {
        "id": "VW5LJczMlo9b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3uK1agbEqcMx"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import NMF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wg_1JwfkqdAq"
      },
      "outputs": [],
      "source": [
        "#Load your nmf_model with the n_components i.e 5\n",
        "num_topics =  5\n",
        "\n",
        "#keep the random_state =40\n",
        "nmf_model = NMF(n_components=num_topics, random_state=40)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nmf_model.fit(dtm)\n",
        "len(tfidf.get_feature_names_out())"
      ],
      "metadata": {
        "id": "OAK1DJ2kEsX3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the top word of a sample component\n",
        "topic_single = nmf_model.components_[0]\n",
        "topic_single.argsort()\n",
        "top_word_index = topic_single.argsort()[-20:]\n",
        "for index in top_word_index:\n",
        "    print(tfidf.get_feature_names_out()[index])"
      ],
      "metadata": {
        "id": "9LWFmya1FLzd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Print the Top20 words for each of the topics\n",
        "for index, topic in enumerate(nmf_model.components_):\n",
        "    print(f'TOP 20 WORDS FOR TOPIC #{index}')\n",
        "    print([tfidf.get_feature_names_out()[i] for i in topic.argsort()[-20:]])\n",
        "    print('\\n')"
      ],
      "metadata": {
        "id": "gxjaSppXFVVm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create the best topic for each complaint in terms of integer value 0,1,2,3 & 4\n",
        "\n",
        "topic_result = nmf_model.transform(dtm)\n",
        "topic_result[0].round(2)\n",
        "topic_result[0].argmax()\n",
        "topic_result.argmax(axis=1)"
      ],
      "metadata": {
        "id": "dgjoiMknFd-X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new 'Topic' column and assign the best topic to each of the complaints\n",
        "\n",
        "df_clean['Topic'] = topic_result.argmax(axis=1)"
      ],
      "metadata": {
        "id": "osbq6sdSF6US"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_clean.shape"
      ],
      "metadata": {
        "id": "JZ1QKuMiF9YH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_clean.head()"
      ],
      "metadata": {
        "id": "xXUlyPUIF_Ko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Print the first 5 Complaint for each of the Topics\n",
        "df_clean_5=df_clean.groupby('Topic').head(5)\n",
        "df_clean_5.sort_values('Topic')"
      ],
      "metadata": {
        "id": "b1LvFe7yGBLy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Mapping Relevant Topic to Each Complaint"
      ],
      "metadata": {
        "id": "YVFo9LAFnvqy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create the dictionary of Topic names and Topics\n",
        "topic_mapping = {\n",
        "    0: 'Bank Account services',\n",
        "    1: 'Credit card or prepaid card',\n",
        "    2: 'Others',\n",
        "    3: 'Theft/Dispute Reporting',\n",
        "    4: 'Mortgage/Loan'\n",
        "}\n",
        "\n",
        "#Replace Topics with Topic Names\n",
        "df_clean['Topic'] = df_clean['Topic'].map(topic_mapping)"
      ],
      "metadata": {
        "id": "Gs5OgdBbGK_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_clean.head()"
      ],
      "metadata": {
        "id": "vTEjDyKpGjM4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot graph to check class imbalance\n",
        "plt.figure(figsize=(12,6))\n",
        "sns.countplot(x='Topic', data=df_clean, color = 'Green')"
      ],
      "metadata": {
        "id": "e48C5WlcGl7N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "unQ_ni95G6cU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. Build the Supervised Model for making a prediction for new complaint"
      ],
      "metadata": {
        "id": "ftJXGweZoTXd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Keep the columns\"complaint_what_happened\" & \"Topic\" only in the new dataframe --> training_data\n",
        "\n",
        "training_data = df_clean[['complaint_text','Topic']]"
      ],
      "metadata": {
        "id": "XSAN6C6WHo3f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data.head()"
      ],
      "metadata": {
        "id": "lQrPfb6tHqQN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data['complaint_text'] = training_data['complaint_text'].str.replace('xxxx','')\n",
        "training_data.head()"
      ],
      "metadata": {
        "id": "y9bKCu6GfhKj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# View value counts of the five topics\n",
        "training_data['Topic'].value_counts()"
      ],
      "metadata": {
        "id": "HNUDN-sjHs9g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10. Data Preprocessing"
      ],
      "metadata": {
        "id": "dIP13hc9or-g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Reverse topic names mapping for supervised learning\n",
        "\n",
        "reverse_topic_mapping = {\n",
        "    'Bank Account services' :0,\n",
        "    'Credit card or prepaid card':1,\n",
        "    'Others':2,\n",
        "    'Theft/Dispute Reporting':3,\n",
        "    'Mortgage/Loan':4\n",
        "}\n",
        "#Replace Topics with Topic Names\n",
        "training_data['Topic'] = training_data['Topic'].map(reverse_topic_mapping)\n",
        "training_data.head()"
      ],
      "metadata": {
        "id": "E0mJhq7NHyw_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Write your code to get the Vector count\n",
        "count_vector=CountVectorizer()\n",
        "\n",
        "#Write your code here to transform the word vector to tf-idf\n",
        "X_train_count=count_vector.fit_transform(training_data['complaint_text'])"
      ],
      "metadata": {
        "id": "VV2lRZ_1IobM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving Word Vector on disk for later usage\n",
        "import pickle\n",
        "\n",
        "pickle.dump(count_vector.vocabulary_, open(\"/content/complaints-2021-05-14_08_16.json\",\"wb\"))"
      ],
      "metadata": {
        "id": "agC75l4eKma1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform the word vector to tf-idf\n",
        "tfidf_transform= TfidfTransformer()\n",
        "X_train_tfidf = tfidf_transform.fit_transform(X_train_count)"
      ],
      "metadata": {
        "id": "7zeb3bOJKx5J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save TF-IDF on disk for later usage\n",
        "pickle.dump(tfidf_transform, open(\"/content/complaints-2021-05-14_08_16.json\",\"wb\"))"
      ],
      "metadata": {
        "id": "Dig1nbE_K2Yo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train-Test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_train_tfidf, training_data.Topic, test_size=0.20, random_state=42)\n",
        "\n",
        "print(f\"X_train Shape: {X_train.shape}\")\n",
        "print(f\"y_train Shape: {y_train.shape}\")\n",
        "print(f\"X_test Shape: {X_test.shape}\")\n",
        "print(f\"y_test Shape: {y_test.shape}\")"
      ],
      "metadata": {
        "id": "lgCMy3JMK7eO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_cPZ1zuiLHPN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 11. Model Building & Evaluation"
      ],
      "metadata": {
        "id": "Ef7JVKUgoxfR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay"
      ],
      "metadata": {
        "id": "Gvguc4WGLyM5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a function to evaluate models\n",
        "def model_eval(y_test, y_pred, model_name):\n",
        "\n",
        "    # print classification report of classifier\n",
        "    print(f\"CLASSIFICATION REPORT for {model_name}\\n\")\n",
        "    print(classification_report(y_test, y_pred, target_names=[\"Bank Account services\", \"Credit card or prepaid card\", \"Others\", \"Theft/Dispute Reporting\",\n",
        "\"Mortgage/Loan\"]))\n",
        "\n",
        "    # plot confusion matrix of the classifier\n",
        "    plt.figure(figsize=(10,7))\n",
        "    plt.title(f\"CONFUSION MATRIX for {model_name}\\n\")\n",
        "    matrix = confusion_matrix(y_test, y_pred)\n",
        "    sns.heatmap(matrix, annot=True, cbar=None, cmap=\"Greens\", fmt='d', xticklabels=[\"Bank Account services\", \"Credit card or prepaid card\", \"Others\", \"Theft/Dispute Reporting\",\n",
        "\"Mortgage/Loan\"], yticklabels=[\"Bank Account services\", \"Credit card or prepaid card\", \"Others\", \"Theft/Dispute Reporting\",\n",
        "\"Mortgage/Loan\"])\n",
        "    plt.show()\n",
        "\n",
        "    return"
      ],
      "metadata": {
        "id": "ZGNVuFU9LzTc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Model 1. Naive Bayes**"
      ],
      "metadata": {
        "id": "321sNO-sMaIS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required library\n",
        "from sklearn.naive_bayes import MultinomialNB"
      ],
      "metadata": {
        "id": "vYDOn2OEL3Ur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the Multinomial Naive Bayes with default parameters\n",
        "\n",
        "model_name = 'NAIVE BAYES'\n",
        "nb = MultinomialNB()\n",
        "nb.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "TuiF_sLTL6Oc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_nb = nb.predict(X_test)"
      ],
      "metadata": {
        "id": "yLWIor3yMAJq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate F1 Score of model using weighted average method\n",
        "f1_nb = f1_score(y_test, y_pred_nb, average=\"weighted\")\n",
        "f1_nb"
      ],
      "metadata": {
        "id": "15W9s4JMMDET"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the Naive Bayes classifier\n",
        "model_eval(y_test, y_pred_nb, model_name)"
      ],
      "metadata": {
        "id": "2B49JySpMIcl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Pkos2r8yMTUj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Model 2. Logistic Regression**"
      ],
      "metadata": {
        "id": "T386U7WgNiA8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required library\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "metadata": {
        "id": "l4kKNpWSMga3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the Logistic Regression model with default parameters\n",
        "model_name = 'LOGISTIC REGRESSION'\n",
        "lr = LogisticRegression()\n",
        "lr.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "mEx049ciMk8k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Making Prediction with test data\n",
        "y_pred_lr = lr.predict(X_test)"
      ],
      "metadata": {
        "id": "LxlWcItlMzwd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate F1 Score of tuned model using weighted average method\n",
        "f1_lr = f1_score(y_test, y_pred_lr, average=\"weighted\")\n",
        "f1_lr"
      ],
      "metadata": {
        "id": "bPdovnYRMnqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the tuned Logistic Regression classifier\n",
        "model_eval(y_test, y_pred_lr, model_name)"
      ],
      "metadata": {
        "id": "9DlAR1cGMsdL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FGdyumo_Mu5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Model 3. Decision Tree**"
      ],
      "metadata": {
        "id": "5efavPS8NgKh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required library\n",
        "from sklearn.tree import DecisionTreeClassifier"
      ],
      "metadata": {
        "id": "kYOupi3-M4K8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run Decision Tree with default hyperparameters\n",
        "model_name = 'DECISION TREE'\n",
        "dt = DecisionTreeClassifier()\n",
        "dt.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "teKSIfZCNp5-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_dt =dt.predict(X_test)"
      ],
      "metadata": {
        "id": "p-5kzxwVNsiY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate F1 Score of tuned model using weighted average method\n",
        "f1_dt = f1_score(y_test, y_pred_dt, average=\"weighted\")\n",
        "f1_dt"
      ],
      "metadata": {
        "id": "ZW24BMX5NtFS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the tuned Decision Tree classifier\n",
        "model_eval(y_test, y_pred_dt, model_name)"
      ],
      "metadata": {
        "id": "35HyxU4FNvdu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6odDdP6zN0BE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Model 4. Random Forest**"
      ],
      "metadata": {
        "id": "4am0d-c8N6R-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required library\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "metadata": {
        "id": "VfDToYHuN8LW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run Decision Tree with default hyperparameters\n",
        "model_name = 'RANDOM FOREST'\n",
        "rf = RandomForestClassifier()\n",
        "rf.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "-gProlqnOG5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Making Prediction on Test Data\n",
        "\n",
        "y_pred_rf =rf.predict(X_test)"
      ],
      "metadata": {
        "id": "v3nWxUnmOUsJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate F1 Score of tuned model using weighted average method\n",
        "f1_rf = f1_score(y_test, y_pred_rf, average=\"weighted\")\n",
        "f1_rf"
      ],
      "metadata": {
        "id": "mHd-UsCpOc8u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the tuned Decision Tree classifier\n",
        "model_eval(y_test, y_pred_rf, model_name)"
      ],
      "metadata": {
        "id": "hDKvoEr_Olll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YZe-JzX3Oqm9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Predicting Category of New Complaint via Logistic Regression on custom text**\n"
      ],
      "metadata": {
        "id": "mEIiPUWhRdvR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save Logistic Regression model as pickle file in device\n",
        "pickle.dump(lr, open(\"/content/complaints-2021-05-14_08_16.json\", \"wb\"))"
      ],
      "metadata": {
        "id": "02b1Nu9FPXZl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xIvEH2jbPd9w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# raw complaint text\n",
        "test_complaint= 'I tried to make a transaction at a supermarket retail store, using my chase \\\n",
        "debit/atm card, but the transaction was declined. I am still able to withdraw money out of an \\\n",
        "ATM machine using the same debit card. Please resolve this issue.'"
      ],
      "metadata": {
        "id": "gHtj13pkQQbn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WUn_YQzuQRIS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vectorize and tf-idf tranform\n",
        "test = count_vector.transform([test_complaint])\n",
        "test_tfidf = tfidf_transform.transform(test)"
      ],
      "metadata": {
        "id": "iLPdWsxRQ2Bj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# predict\n",
        "prediction=lr.predict(test_tfidf)\n",
        "prediction"
      ],
      "metadata": {
        "id": "TKtGcxxnRQx6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "topic_mapping[prediction[0]]"
      ],
      "metadata": {
        "id": "S3POjsP6RWxU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Create a list of Custom Complaints and then Predict the Category of Each Complaint**"
      ],
      "metadata": {
        "id": "oPhHC03YSTdm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to predict a topic for custom text\n",
        "\n",
        "def topic_predictor(text):\n",
        "\n",
        "    target_names = [\"Bank Account services\", \"Credit card or prepaid card\", \"Others\", \"Theft/Dispute Reporting\", \"Mortgage/Loan\"]\n",
        "\n",
        "    load_vec = CountVectorizer(vocabulary=pickle.load(open(\"/content/drive/MyDrive/Case Study NLP - Automatic Ticket Classification/count_vector.pkl\", \"rb\")))\n",
        "    load_tfidf = pickle.load(open(\"/content/drive/MyDrive/Case Study NLP - Automatic Ticket Classification/tfidf.pkl\",\"rb\"))\n",
        "    load_model = pickle.load(open(\"/content/drive/MyDrive/Case Study NLP - Automatic Ticket Classification/logreg_model.pkl\",\"rb\"))\n",
        "\n",
        "    X_new_count = load_vec.transform(text)\n",
        "    X_new_tfidf = load_tfidf.transform(X_new_count)\n",
        "    prediction = load_model.predict(X_new_tfidf)\n",
        "\n",
        "    return target_names[prediction[0]]"
      ],
      "metadata": {
        "id": "n39n609BQZb5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dataframe of some sample customer complaints\n",
        "import pandas as pd\n",
        "df_custom = pd.DataFrame({'complaints': [\"I can not get from chase who services my mortgage, who owns it and who has original loan docs\",\n",
        "                                  \"The bill amount of my credit card was debited twice. Please look into the matter and resolve at the earliest.\",\n",
        "                                  \"I want to open a salary account at your downtown branch. Please provide me the procedure.\",\n",
        "                                  \"unwanted service activated and money deducted automatically \",\n",
        "                                  \"How can I know my CIBIL score?\",\n",
        "                                  \"Where are the bank branches in the city of Patna?\"]})\n",
        "df_custom"
      ],
      "metadata": {
        "id": "vslpIjVgQuSM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new column of predicted topics of each complaint, predicted using the tuned Logistic Regression model\n",
        "df_custom['Predicted Category'] = df_custom['complaints'].apply(lambda x: topic_predictor([x]))\n",
        "df_custom"
      ],
      "metadata": {
        "id": "x1vCni21Q1K2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***We conclude that the Logistic Regression model is best for making a prediction on custom complaints data.***"
      ],
      "metadata": {
        "id": "wDu4dJPkSwIK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio\n",
        "import gradio as gr\n",
        "\n",
        "# Function to predict a topic for custom text\n",
        "\n",
        "def topic_predictor(text):\n",
        "\n",
        "    target_names = [\"Bank Account services\", \"Credit card or prepaid card\", \"Others\", \"Theft/Dispute Reporting\", \"Mortgage/Loan\"]\n",
        "\n",
        "    complaint_text = clean_texts(text)\n",
        "    complaint_text = lemma_texts(complaint_text)\n",
        "    complaint_text = singular_nouns(complaint_text)\n",
        "    X_new_count = count_vector.transform([complaint_text])\n",
        "    X_new_tfidf = tfidf_transform.transform(X_new_count)\n",
        "    prediction = lr.predict(X_new_tfidf)\n",
        "\n",
        "    return target_names[prediction[0]]\n",
        "\n",
        "\n",
        "# Create a Gradio Interface\n",
        "interface = gr.Interface(\n",
        "    fn=topic_predictor,  # Function for prediction\n",
        "    inputs=\"text\",       # Input type: text\n",
        "    outputs=\"text\",      # Output type: text\n",
        "    title=\"Automatic Ticket Classification Model\",\n",
        "    description=\"Enter a text and the model will automatically classify the category of complaints.\",\n",
        "    theme=gr.themes.Base(\n",
        "        primary_hue=\"blue\",          # Primary button and accent color\n",
        "        secondary_hue=\"gray\",        # Secondary elements\n",
        "        neutral_hue=\"indigo\",        # Neutral elements (e.g., borders)\n",
        "        text_size=\"lg\"               # Text size\n",
        "    )\n",
        ")\n",
        "\n",
        "# Launch the app\n",
        "interface.launch()"
      ],
      "metadata": {
        "id": "TUXOesbzlYtJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}